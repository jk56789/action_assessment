{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap1 = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret1, frame1 = cap1.read()\n",
    "  \n",
    "    cv2.imshow('st', frame1)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap1.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상 path 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/jk/action_assess/data/video/keypoints/313-2-1-15-Z75_D.avi'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "## Trainer 경로\n",
    "raw_root_dir ='C:/Users/jk/action_assess/data/video/keypoints/'\n",
    "video_name = '313-2-1-15-Z75_D.avi'\n",
    "input_video_dir = os.path.join(raw_root_dir,video_name)\n",
    "input_video_dir\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 좌우 flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap1 = cv2.VideoCapture(input_video_dir)\n",
    "# 두 비디오의 속성 가져오기\n",
    "frame_width1 = int(cap1.get(3))\n",
    "frame_height1 = int(cap1.get(4))\n",
    "\n",
    "while True:\n",
    "    ret1, frame1 = cap1.read()\n",
    "    if not ret1:\n",
    "        break\n",
    "\n",
    "    # 좌우 반전 추가\n",
    "    frame1 = cv2.flip(frame1, 1)\n",
    "  \n",
    "    cv2.imshow('st', frame1)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap1.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080 1920\n"
     ]
    }
   ],
   "source": [
    "print(frame_width1,frame_height1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os \n",
    "\n",
    "raw_root_dir = 'C:/Users/jk/action_assess/data/video/output/'\n",
    "video_name = '90_up_1.mp4'\n",
    "input_video_dir = os.path.join(raw_root_dir,video_name)\n",
    "\n",
    "# 비디오 캡처 시작\n",
    "cap1 = cv2.VideoCapture(input_video_dir)\n",
    "\n",
    "# 캡처되는 비디오의 속성을 가져옴\n",
    "frame_width = int(cap1.get(3))\n",
    "frame_height = int(cap1.get(4))\n",
    "\n",
    "# VideoWriter 객체 생성\n",
    "out = cv2.VideoWriter('C:/Users/jk/action_assess/data/video/output/90_up_1_flip_squat.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30.0, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    ret1, frame1 = cap1.read()\n",
    "    if not ret1:\n",
    "        break\n",
    "\n",
    "    # 좌우 반전 추가\n",
    "    frame1 = cv2.flip(frame1, 1)\n",
    "    # 프레임 저장\n",
    "    out.write(frame1)\n",
    "\n",
    "    cv2.imshow('st', frame1)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 자원 해제\n",
    "cap1.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상 좌우 concat, 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def concatenate_three_videos_vertically(video1_path, video2_path, video3_path, output_path):\n",
    "    cap1 = cv2.VideoCapture(video1_path)\n",
    "    cap2 = cv2.VideoCapture(video2_path)\n",
    "    cap3 = cv2.VideoCapture(video3_path)\n",
    "\n",
    "    frame_width1 = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height1 = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_width2 = int(cap2.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height2 = int(cap2.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_width3 = int(cap3.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height3 = int(cap3.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    frame_width = min(frame_width1, frame_width2, frame_width3)\n",
    "    frame_height = frame_height1 + frame_height2 + frame_height3\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 3.0, (frame_width, frame_height))\n",
    "\n",
    "    while True:\n",
    "        ret1, frame1 = cap1.read()\n",
    "        ret2, frame2 = cap2.read()\n",
    "        ret3, frame3 = cap3.read()\n",
    "\n",
    "        if not ret1 or not ret2 or not ret3:\n",
    "            break\n",
    "\n",
    "        frame1 = cv2.resize(frame1, (frame_width, frame_height1))\n",
    "        frame2 = cv2.resize(frame2, (frame_width, frame_height2))\n",
    "        frame3 = cv2.resize(frame3, (frame_width, frame_height3))\n",
    "\n",
    "        combined_frame = np.vstack((frame1, frame2, frame3))\n",
    "\n",
    "        cv2.imshow('Combined Stream', combined_frame)\n",
    "        out.write(combined_frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    cap3.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "video1_path = 'C:/Users/jk/action_assess/experiment1/data/squat/person5/results/325_gt_error_shifted(original).avi'\n",
    "video2_path = 'C:/Users/jk/action_assess/experiment1/data/squat/person5/results/325_gt_error_shifted(cs).avi'\n",
    "video3_path = 'C:/Users/jk/action_assess/experiment1/data/squat/person5/results/325_gt_error_shifted(DTW).avi'\n",
    "output_path = 'C:/Users/jk/action_assess/experiment1/data/squat/person5/results/325_concat_three.avi'\n",
    "\n",
    "concatenate_three_videos_vertically(video1_path, video2_path, video3_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def concatenate_three_videos_vertically(video1_path, video2_path, video3_path, output_path, start_frame=10):\n",
    "    cap1 = cv2.VideoCapture(video1_path)\n",
    "    cap2 = cv2.VideoCapture(video2_path)\n",
    "    cap3 = cv2.VideoCapture(video3_path)\n",
    "\n",
    "    # Set the starting frame\n",
    "    cap1.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    cap2.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    cap3.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    frame_width1 = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height1 = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_width2 = int(cap2.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height2 = int(cap2.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_width3 = int(cap3.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height3 = int(cap3.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    frame_width = min(frame_width1, frame_width2, frame_width3)\n",
    "    frame_height = frame_height1 + frame_height2 + frame_height3\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 3.0, (frame_width, frame_height))\n",
    "\n",
    "    while True:\n",
    "        ret1, frame1 = cap1.read()\n",
    "        ret2, frame2 = cap2.read()\n",
    "        ret3, frame3 = cap3.read()\n",
    "\n",
    "        if not ret1 or not ret2 or not ret3:\n",
    "            break\n",
    "\n",
    "        frame1 = cv2.resize(frame1, (frame_width, frame_height1))\n",
    "        frame2 = cv2.resize(frame2, (frame_width, frame_height2))\n",
    "        frame3 = cv2.resize(frame3, (frame_width, frame_height3))\n",
    "\n",
    "        combined_frame = np.vstack((frame1, frame2, frame3))\n",
    "\n",
    "        cv2.imshow('Combined Stream', combined_frame)\n",
    "        out.write(combined_frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    cap3.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "video1_path = 'C:/Users/jk/action_assess/experiment1/data/squat/person5/results/325_gt_error_shifted(original).avi'\n",
    "video2_path = 'C:/Users/jk/action_assess/experiment1/data/squat/person5/results/325_gt_error_shifted(cs).avi'\n",
    "video3_path = 'C:/Users/jk/action_assess/experiment1/data/squat/person5/results/325_gt_error_shifted(DTW).avi'\n",
    "output_path = 'C:/Users/jk/action_assess/experiment1/data/squat/person5/results/325_concat_three.avi'\n",
    "\n",
    "concatenate_three_videos_vertically(video1_path, video2_path, video3_path, output_path, start_frame=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 두 개의 비디오 캡처 객체 생성\n",
    "\n",
    "cap1 = cv2.VideoCapture('C:/Users/jk/action_assess/experiment1/data/squat/person5/results/322_gt_normal.avi')  # 첫 번째 카메라\n",
    "cap2 = cv2.VideoCapture('C:/Users/jk/action_assess/experiment1/data/squat/person5/results/322_gt_normal_shifted.avi')    # 두 번째 카메라\n",
    "\n",
    "# 두 비디오의 속성 가져오기\n",
    "frame_width1 = int(cap1.get(3))\n",
    "frame_height1 = int(cap1.get(4))\n",
    "frame_width2 = int(cap2.get(3))\n",
    "frame_height2 = int(cap2.get(4))\n",
    "\n",
    "# 두 비디오의 크기를 동일하게 설정 (더 작은 크기로 조정)\n",
    "frame_width = min(frame_width1, frame_width2)\n",
    "frame_height = min(frame_height1, frame_height2)\n",
    "\n",
    "# VideoWriter 객체 생성\n",
    "out = cv2.VideoWriter('C:/Users/jk/action_assess/experiment1/data/squat/person5/results/322_concat.avi',\n",
    "                       cv2.VideoWriter_fourcc(*'XVID'), 3.0, (frame_width, frame_height * 2 ))\n",
    "\n",
    "while True:\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "\n",
    "    if not ret1 or not ret2:\n",
    "        break\n",
    "\n",
    "    # 프레임 크기 조정\n",
    "    frame1 = cv2.resize(frame1, (frame_width, frame_height))\n",
    "    frame2 = cv2.resize(frame2, (frame_width, frame_height))\n",
    "\n",
    "    # 두 프레임을 좌우로 결합\n",
    "    #combined_frame = np.hstack((frame1, frame2))\n",
    "    \n",
    "    # 두 프레임을 상하로 결합\n",
    "    combined_frame = np.vstack((frame1, frame2))\n",
    "\n",
    "    # 결합된 프레임을 출력\n",
    "    cv2.imshow('Combined Stream', combined_frame)\n",
    "\n",
    "    # 결합된 프레임을 저장\n",
    "    out.write(combined_frame)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 자원 해제\n",
    "cap1.release()\n",
    "cap2.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def images_to_video(image_folder, output_video_path, fps=30):\n",
    "    images = [img for img in os.listdir(image_folder) if img.endswith(\".png\") or img.endswith(\".jpg\")]\n",
    "    images.sort()  # Ensure the images are in the correct order\n",
    "\n",
    "    frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(output_video_path, fourcc, 2, (width, height))\n",
    "\n",
    "    for image in images:\n",
    "        video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "    video.release()\n",
    "\n",
    "def concatenate_videos_vertically(video1_path, video2_path, output_path):\n",
    "    cap1 = cv2.VideoCapture(video1_path)\n",
    "    cap2 = cv2.VideoCapture(video2_path)\n",
    "\n",
    "    frame_width1 = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height1 = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_width2 = int(cap2.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height2 = int(cap2.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    frame_width = min(frame_width1, frame_width2)\n",
    "    frame_height = frame_height1 + frame_height2\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 2, (frame_width, frame_height))\n",
    "\n",
    "    while True:\n",
    "        ret1, frame1 = cap1.read()\n",
    "        ret2, frame2 = cap2.read()\n",
    "\n",
    "        if not ret1 or not ret2:\n",
    "            break\n",
    "\n",
    "        frame1 = cv2.resize(frame1, (frame_width, frame_height1))\n",
    "        frame2 = cv2.resize(frame2, (frame_width, frame_height2))\n",
    "\n",
    "        combined_frame = np.vstack((frame1, frame2))\n",
    "        out.write(combined_frame)\n",
    "\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage:\n",
    "image_folder = 'C:/Users/jk/action_assess/experiment1/data/squat/person5/results-all/319'\n",
    "existing_video_path = 'C:/Users/jk/action_assess/experiment1/data/squat/person5/results/320_gt_normal_2.avi'\n",
    "temp_video_path = 'temp_video_from_images.mp4'\n",
    "output_video_path = 'concatenated_video.mp4'\n",
    "\n",
    "# Convert images to video\n",
    "images_to_video(image_folder, temp_video_path)\n",
    "\n",
    "# Concatenate the existing video and the new video from images\n",
    "concatenate_videos_vertically(existing_video_path, temp_video_path, output_video_path)\n",
    "\n",
    "# Optionally, delete the temporary video file\n",
    "os.remove(temp_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def concat_videos(input_dir, output_dir):\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # List all files in the input directory\n",
    "    files = os.listdir(input_dir)\n",
    "    \n",
    "    # Filter out the original and shifted video pairs\n",
    "    original_files = [f for f in files if 'original' in f]\n",
    "    shifted_files = [f for f in files if 'shifted' in f]\n",
    "    \n",
    "    for original_file in original_files:\n",
    "        base_name = original_file.replace('_original.avi', '')\n",
    "        shifted_file = f\"{base_name}_shifted.avi\"\n",
    "        \n",
    "        if shifted_file in shifted_files:\n",
    "            original_path = os.path.join(input_dir, original_file)\n",
    "            shifted_path = os.path.join(input_dir, shifted_file)\n",
    "            output_path = os.path.join(output_dir, f\"{base_name}_concat.avi\")\n",
    "            \n",
    "            # Create video capture objects\n",
    "            cap1 = cv2.VideoCapture(original_path)\n",
    "            cap2 = cv2.VideoCapture(shifted_path)\n",
    "            \n",
    "            # Get video properties\n",
    "            frame_width1 = int(cap1.get(3))\n",
    "            frame_height1 = int(cap1.get(4))\n",
    "            frame_width2 = int(cap2.get(3))\n",
    "            frame_height2 = int(cap2.get(4))\n",
    "            \n",
    "            # Set the frame size to the smaller of the two videos\n",
    "            frame_width = min(frame_width1, frame_width2)\n",
    "            frame_height = min(frame_height1, frame_height2)\n",
    "            \n",
    "            # Create VideoWriter object\n",
    "            out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), 3.0, (frame_width, frame_height * 2))\n",
    "            \n",
    "            while True:\n",
    "                ret1, frame1 = cap1.read()\n",
    "                ret2, frame2 = cap2.read()\n",
    "                \n",
    "                if not ret1 or not ret2:\n",
    "                    break\n",
    "                \n",
    "                # Resize frames\n",
    "                frame1 = cv2.resize(frame1, (frame_width, frame_height))\n",
    "                frame2 = cv2.resize(frame2, (frame_width, frame_height))\n",
    "                \n",
    "                # Concatenate frames vertically\n",
    "                combined_frame = np.vstack((frame1, frame2))\n",
    "                \n",
    "                # Write the combined frame\n",
    "                out.write(combined_frame)\n",
    "                \n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            \n",
    "            # Release resources\n",
    "            cap1.release()\n",
    "            cap2.release()\n",
    "            out.release()\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Define input and output directories\n",
    "input_dir = 'C:/Users/jk/action_assess/experiment1/data/squat/person5/results/'\n",
    "output_dir = 'C:/Users/jk/action_assess/experiment1/data/squat/person5/results/concat/'\n",
    "\n",
    "# Run the concatenation process\n",
    "concat_videos(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def add_text_to_frame(frame, text, position, font=cv2.FONT_HERSHEY_SIMPLEX, font_scale=1, color=(0, 0, 0), thickness=2):\n",
    "    return cv2.putText(frame, text, position, font, font_scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "def concatenate_videos(input_dir, output_path):\n",
    "    # List all video files in the input directory\n",
    "    video_files = [f for f in os.listdir(input_dir) if f.endswith('.avi') or f.endswith('.mp4')]\n",
    "    video_files.sort()  # Ensure the videos are in the correct order\n",
    "\n",
    "    # Initialize variables\n",
    "    frames = []\n",
    "    frame_width, frame_height = 0, 0\n",
    "    fps = 30  # Default FPS, will be updated based on the first video\n",
    "\n",
    "    for video_file in video_files:\n",
    "        video_path = os.path.join(input_dir, video_file)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error opening video file {video_file}\")\n",
    "            continue\n",
    "\n",
    "        # Get video properties\n",
    "        if frame_width == 0 or frame_height == 0:\n",
    "            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Calculate the position for the text to be centered\n",
    "            text_size = cv2.getTextSize(video_file, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)[0]\n",
    "            text_x = (frame.shape[1] - text_size[0]) // 2\n",
    "            text_y = (frame.shape[0] + text_size[1]) // 2\n",
    "\n",
    "            # Add text to each frame\n",
    "            frame = add_text_to_frame(frame, video_file, position=(text_x, text_y))\n",
    "\n",
    "            frames.append(frame)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "    # Create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 10, (frame_width, frame_height))\n",
    "\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Define input and output directories\n",
    "input_dir = 'C:/Users/jk/action_assess/experiment1/data/squat/person5/results/concat/'\n",
    "output_path = 'C:/Users/jk/action_assess/experiment1/data/squat/person5/results/concat/combined_output.avi'\n",
    "\n",
    "# Run the concatenation process\n",
    "concatenate_videos(input_dir, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상 resize, 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 웹캠에서 비디오 캡처 시작\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 조정할 새로운 크기 설정\n",
    "new_width = 1280\n",
    "new_height = 480\n",
    "\n",
    "# VideoWriter 객체 생성\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('resized_output.avi', fourcc, 20.0, (new_width, new_height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 프레임의 크기를 조정\n",
    "    resized_frame = cv2.resize(frame, (new_width, new_height))\n",
    "\n",
    "    # 조정된 프레임을 출력\n",
    "    cv2.imshow('Resized Frame', resized_frame)\n",
    "\n",
    "    # 조정된 프레임을 파일로 저장\n",
    "    out.write(resized_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 자원 해제\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상 raw clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_to_csv(data):\n",
    "    output_csv_dir = 'C:/Users/jk/action_assess/data/csv/test.csv'\n",
    "    with open(output_csv_dir, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_num | type | angle\n",
      "------------------------------\n",
      "'up' frame: 491 /  angle: 180\n",
      "------------------------------\n",
      "'up' frame: 1133 /  angle: 180\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def process_video(input_video_dir):\n",
    "    cap = cv2.VideoCapture(input_video_dir)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cv2.imshow('Video', frame)\n",
    "        key = cv2.waitKey(10)  \n",
    "\n",
    "        if key == ord('q'): \n",
    "            break\n",
    "\n",
    "        angle = 180\n",
    "        if key == ord(' '):\n",
    "            write_to_csv(['frame_num', 'type', 'angle'])\n",
    "            print(\"frame_num |\", 'type |', 'angle')\n",
    "            print(\"-\"*30)\n",
    "\n",
    "        elif key == ord('w'):\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            write_to_csv([frame_count, 'up', angle])\n",
    "            print(\"'up' frame:\", frame_count, \"/  angle:\", angle)\n",
    "            print(\"-\"*30)\n",
    "\n",
    "        elif key == ord('d'):\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "            write_to_csv([frame_count, 'down', angle])\n",
    "            print(\"'down' frame:\", frame_count, \"/  angle:\", angle)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "raw_root_dir = 'C:/Users/jk/action_assess/data/video/raw/'\n",
    "video_name = 'squat_up_set3.mp4'\n",
    "input_video_dir = os.path.join(raw_root_dir,video_name)\n",
    "\n",
    "process_video(input_video_dir)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상 clip 자르기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "def trim_video(input_video_path, output_video_path, start_frame, end_frame):\n",
    "    # Initialize video captu re\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use appropriate codec\n",
    "    \n",
    "    # Initialize video writer\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    # Set initial frame\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "    \n",
    "    current_frame = start_frame\n",
    "    while current_frame <= end_frame:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        out.write(frame)\n",
    "        current_frame += 1\n",
    "    \n",
    "    # Release everything when job is finished\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "raw_root_dir = 'C:/Users/jk/action_assess/data/video/raw/'\n",
    "output_root_dir = 'C:/Users/jk/action_assess/data/video/output/'\n",
    "video_name = 'squat_up_set3.mp4'\n",
    "input_video_dir = os.path.join(raw_root_dir,video_name)\n",
    "output_video_dir = os.path.join(output_root_dir,video_name)\n",
    "\n",
    "start_frame = 421\n",
    "finish_frame = 1113\n",
    "trim_video(input_video_dir, output_video_dir, start_frame, finish_frame)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "action_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
