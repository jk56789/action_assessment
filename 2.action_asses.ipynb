{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import jk_module\n",
    "import sys\n",
    "sys.path.append('D:/bagel/action_assessment/jk_OKS.py')\n",
    "import jk_OKS\n",
    "import jk_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image loaded successfully\n"
     ]
    }
   ],
   "source": [
    "frame2 = cv2.imread('img.png')\n",
    "if frame2 is None:\n",
    "    print(f\"Failed to load image from {image_dir}\")\n",
    "else:\n",
    "    print(\"Image loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n",
      "Failed to read from cap0\n",
      "ok\n",
      "ok\n",
      "Failed to read from cap0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import jk_module\n",
    "'''import sys\n",
    "sys.path.append('D:/bagel/action_project2/jk_OKS.py')'''\n",
    "import jk_OKS\n",
    "import jk_draw\n",
    "\n",
    "import time\n",
    "'''\n",
    "import jk_vector\n",
    "import jk_angle\n",
    "import jk_DTW\n",
    "\n",
    "\n",
    "import ast\n",
    "import csv\n",
    "from dtaidistance import dtw'''\n",
    "\n",
    "\n",
    "\n",
    "## Trainer 경로\n",
    "raw_root_dir = 'G:/공유 드라이브/R&D/DEX-001 (DEXULIN)/AI 자료/0.연구자료/action_assessment_data/' \n",
    "\n",
    "trainer_video_name = 'trainer_keypoints.mp4'\n",
    "trainer_video_dir = os.path.join(raw_root_dir,trainer_video_name)\n",
    "\n",
    "cap0 = cv2.VideoCapture(trainer_video_dir)\n",
    "width0 = int(cap0.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height0 = int(cap0.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "## User 경로\n",
    "for trial in range(2, 4):\n",
    "    user_video_name = f'user/user_{trial}.mp4'\n",
    "    user_video_dir = os.path.join(raw_root_dir,user_video_name)\n",
    "\n",
    "    cap1 = cv2.VideoCapture(user_video_dir)\n",
    "    width1 = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height1 = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Trainer 비디오 파일 열기\n",
    "    cap0 = cv2.VideoCapture(trainer_video_dir)\n",
    "    if cap0.isOpened():\n",
    "        print(\"ok\")\n",
    "    else:\n",
    "        print(\"failed\")\n",
    "\n",
    "    # 카메라 장치 열기\n",
    "\n",
    "    if cap1.isOpened():\n",
    "        print(\"ok\")\n",
    "    else:\n",
    "        print(\"failed\")\n",
    "\n",
    "    # 두 비디오의 크기를 동일하게 설정 (더 작은 크기로 조정)\n",
    "    frame_width = min(width0, width1)\n",
    "    frame_height = min(height0, height1)\n",
    "\n",
    "\n",
    "    # frame 크기 변경하여 시각화 및 저장(입력은 입력 이미지 사용)\n",
    "    # 입력 (1080,1920)\n",
    "    new_width = 1240\n",
    "    new_height = 720\n",
    "    \n",
    "    # 경로 설정\n",
    "    data_dir = os.path.join(raw_root_dir, 'data')\n",
    "\n",
    "    # data 폴더가 없으면 생성\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "\n",
    "    # VideoWriter 객체 생성을 위한 설정\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    trainer_output_video_name = f'trainer_output_{trial}.mp4'\n",
    "    trainer_video_output_dir = os.path.join(data_dir, trainer_output_video_name)\n",
    "    out = cv2.VideoWriter(trainer_video_output_dir, fourcc, 12.0, (new_width, new_height))\n",
    "\n",
    "    '''# VideoWriter 객체 생성을 위한 설정\n",
    "    user_output_video_name = f'user_{trial}.mp4'\n",
    "    user_video_output_dir = os.path.join(raw_trainer_root_dir, user_output_video_name)\n",
    "    user_out = cv2.VideoWriter(user_video_output_dir, fourcc, 3.0, (width1 , height1 ))\n",
    "    '''\n",
    "    # 미디어 파이프 모델 선택\n",
    "    mp_drawing = mp.solutions.drawing_utils \n",
    "    mp_pose = mp.solutions.pose\n",
    "\n",
    "    # score board\n",
    "    image_name = 'image.png'\n",
    "    image_dir = os.path.join(raw_root_dir,image_name)\n",
    "    frame2 = cv2.imread('img.png')\n",
    "\n",
    "    # trainer 데이터 로드\n",
    "    csv_results_name = 'csv/trainer_results.csv'\n",
    "    csv_results_path =  os.path.join(raw_root_dir,csv_results_name)\n",
    "    \n",
    "    csv_world_results_name = 'csv/trainer_world_results.csv'\n",
    "    csv_world_results_path =  os.path.join(raw_root_dir,csv_world_results_name)\n",
    "    \n",
    "    trainer_results_df = pd.read_csv(csv_results_path)\n",
    "    trainer_world_results_df = pd.read_csv(csv_world_results_path)\n",
    "\n",
    "    # user 데이터\n",
    "    user_base_results_df = trainer_results_df.copy()\n",
    "    user_world_results_df = trainer_world_results_df.copy()\n",
    "\n",
    "    row = 0\n",
    "\n",
    "    # main code\n",
    "    with mp_pose.Pose(min_detection_confidence=0.9, min_tracking_confidence=0.9) as pose:\n",
    "        '''previous_frame0 = None\n",
    "        previous_frame1 = None'''\n",
    "        \n",
    "        while True:\n",
    "            ret0, frame0 = cap0.read()\n",
    "            if not ret0:\n",
    "                print(\"Failed to read from cap0\")\n",
    "                break\n",
    "            ret1, frame1 = cap1.read()\n",
    "            if not ret1:\n",
    "                print(\"Failed to read from cap1\")\n",
    "                break\n",
    "            # 시작 시점 측정\n",
    "            start_t = timeit.default_timer()\n",
    "            \n",
    "            #############################################################\n",
    "            ## Trainer 이미지 처리 (image0)\n",
    "            image0 = frame0\n",
    "            image1 = frame1\n",
    "            \n",
    "            \n",
    "            ############################################################\n",
    "            ## User 이미지 처리 (image1)\n",
    "            # Flip frame1 horizontally\n",
    "            #frame1_flipped = cv2.flip(frame1, 1)\n",
    "            frame1_flipped_resized = cv2.resize(frame1, (822, 586))\n",
    "            \n",
    "            try:\n",
    "                # Now use frame1_flipped for further processing\n",
    "                image1, results1 = jk_module.mediapipe_detection(frame1_flipped_resized, pose)\n",
    "                mp_drawing.draw_landmarks(image1, results1.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                        mp_drawing.DrawingSpec(color=(0,66,230), thickness=6, circle_radius=4), \n",
    "                                        mp_drawing.DrawingSpec(color=(0,0,255), thickness=6, circle_radius=4)) \n",
    "                landmarks = results1.pose_landmarks.landmark\n",
    "                world_landmarks = results1.pose_world_landmarks.landmark\n",
    "                \n",
    "                #csv_results_path = f'user_results{trial}.csv'\n",
    "                #csv_world_results_path =  f'user_world_results1{trial}.csv'\n",
    "                #jk_module.landmarks_save(csv_results_path, results1, row)\n",
    "                #jk_module.world_landmarks_save(csv_world_results_path, results1, row)\n",
    "\n",
    "                # Continue with the rest of your code, ensuring to use the flipped image where necessary\n",
    "            except:\n",
    "                pass\n",
    "            ############################################################\n",
    "            ## 데이터 로드\n",
    "            if row >= len(trainer_world_results_df):\n",
    "                break\n",
    "                \n",
    "            now_trainer_world = trainer_world_results_df.iloc[row].tolist()\n",
    "            now_trainer_base = trainer_results_df.iloc[row].tolist()\n",
    "\n",
    "            now_user_world = [coord for w_landmark in world_landmarks for coord in (w_landmark.x, w_landmark.y, w_landmark.z, w_landmark.visibility)]\n",
    "            #now_user_base = [coord for landmark in landmarks for coord in (landmark.x, landmark.y, landmark.z, landmark.visibility)]\n",
    "\n",
    "            now_user_base = []\n",
    "            for landmark in landmarks:\n",
    "                now_user_base.extend([landmark.x , landmark.y, landmark.z, landmark.visibility])\n",
    "            \n",
    "            user_world_results_df.loc[row] = now_user_world\n",
    "            user_base_results_df.loc[row] = now_user_base\n",
    "            \n",
    "            \n",
    "            \n",
    "            ###평가\n",
    "            ############################################################\n",
    "            ##2. score board 이미지 처리 (image2)\n",
    "            image2 = cv2.resize(frame2, (frame_width, frame_height))\n",
    "\n",
    "            \"\"\"입력\"\"\"\n",
    "            columns = [23,25,11,13,15,27, 24,26,12,14,16,28]\n",
    "            #OKS_list = jk_OKS.OKS_score(now_trainer_world, now_user_world, columns)\n",
    "            OKS_list_base = jk_OKS.OKS_2d_score(now_trainer_base, now_user_base, columns)\n",
    "            #jk_OKS.OkS_text(image2, OKS_list)\n",
    "\n",
    "            jk_OKS.OkS_text_base3(image2, OKS_list_base)\n",
    "\n",
    "\n",
    "            ############################################################\n",
    "            ##3. visual 이미지 처리 (image3)\n",
    "            image3 = np.ones((frame_height, frame_width, 3), dtype=np.uint8) * 255\n",
    "            \n",
    "            image3 = jk_draw.draw_person2(image3, now_trainer_base, frame_width, frame_height)\n",
    "            image3 = jk_draw.draw_person2(image3, now_user_base, frame_width, frame_height, color_keypoint=(0,66,230), color_connection=(0,0,255))\n",
    "                    \n",
    "\n",
    "            ############################################################\n",
    "            ##4. concat 두 프레임을 좌우 결합\n",
    "            # Ensure all images are resized to the same height and width before concatenation\n",
    "            image0_resized = cv2.resize(image0, (frame_width, frame_height))\n",
    "            image1_resized = cv2.resize(image1, (frame_width, frame_height))\n",
    "            image2_resized = cv2.resize(image2, (frame_width, frame_height))\n",
    "            image3_resized = cv2.resize(image3, (frame_width, frame_height))\n",
    "\n",
    "            # Concatenate the resized images\n",
    "            combined_frame = np.hstack((image0_resized, image1_resized, image2_resized, image3_resized))\n",
    "            \n",
    "\n",
    "            # 프레임의 크기 조정\n",
    "            resized_frame = cv2.resize(combined_frame, (new_width, new_height))\n",
    "            ############################################################\n",
    "            ##5.시간 측정\n",
    "            # 종료 시점 측정\n",
    "            end_t = timeit.default_timer()\n",
    "            FPS = 1./(end_t - start_t )\n",
    "\n",
    "            #cv2.putText(resized_frame,f'FPS: {FPS:.2f}', (300,50), cv2.FONT_ITALIC, 1, (255,0,0), 2)\n",
    "            \n",
    "            # 조정된 프레임을 파일로 저장\n",
    "            out.write(resized_frame)\n",
    "            #user_out.write(frame1_flipped)\n",
    "            cv2.imshow('test', resized_frame)\n",
    "            \n",
    "            #time.sleep(0.1)\n",
    "            \n",
    "            row = row + 1\n",
    "\n",
    "            \n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            \n",
    "        cap0.release()\n",
    "        cap1.release()\n",
    "        out.release()  \n",
    "        #user_out.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import jk_module\n",
    "'''import sys\n",
    "sys.path.append('D:/bagel/action_project2/jk_OKS.py')'''\n",
    "import jk_OKS\n",
    "import jk_draw\n",
    "\n",
    "import time\n",
    "'''\n",
    "import jk_vector\n",
    "import jk_angle\n",
    "import jk_DTW\n",
    "\n",
    "\n",
    "import ast\n",
    "import csv\n",
    "from dtaidistance import dtw'''\n",
    "\n",
    "\n",
    "\n",
    "## Trainer 경로\n",
    "raw_root_dir = 'G:/공유 드라이브/R&D/DEX-001 (DEXULIN)/AI 자료/0.연구자료/action_assessment_data/' \n",
    "\n",
    "trainer_video_name = 'trainer_keypoints.mp4'\n",
    "trainer_video_dir = os.path.join(raw_root_dir,trainer_video_name)\n",
    "\n",
    "cap0 = cv2.VideoCapture(trainer_video_dir)\n",
    "width0 = int(cap0.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height0 = int(cap0.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Trainer 비디오 파일 열기\n",
    "cap0 = cv2.VideoCapture(trainer_video_dir)\n",
    "if cap0.isOpened():\n",
    "    print(\"ok\")\n",
    "else:\n",
    "    print(\"failed\")\n",
    "\n",
    "## User 경로\n",
    "cap1 = cv2.VideoCapture(0)\n",
    "width1 = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height1 = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# 카메라 장치 열기\n",
    "if cap1.isOpened():\n",
    "    print(\"ok\")\n",
    "else:\n",
    "    print(\"failed\")\n",
    "\n",
    "# 두 비디오의 크기를 동일하게 설정 (더 작은 크기로 조정)\n",
    "frame_width = min(width0, width1)\n",
    "frame_height = min(height0, height1)\n",
    "\n",
    "\n",
    "# frame 크기 변경하여 시각화 및 저장(입력은 입력 이미지 사용)\n",
    "# 입력 (1080,1920)\n",
    "new_width = 1240\n",
    "new_height = 720\n",
    "\n",
    "# 경로 설정\n",
    "data_dir = os.path.join(raw_root_dir, 'data')\n",
    "\n",
    "# data 폴더가 없으면 생성\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "trial = 0\n",
    "\n",
    "# VideoWriter 객체 생성을 위한 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(f'trainer_output_all_{trial}.mp4', fourcc, 12.0, (new_width, new_height))\n",
    "\n",
    "# VideoWriter 객체 생성을 위한 설정\n",
    "user_out = cv2.VideoWriter(f'user_{trial}.mp4', fourcc, 3.0, (width0 , height0 ))\n",
    "\n",
    "\n",
    "# 미디어 파이프 모델 선택\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# score board\n",
    "image_name = 'image.png'\n",
    "image_dir = os.path.join(raw_root_dir,image_name)\n",
    "frame2 = cv2.imread('img.png')\n",
    "\n",
    "    # trainer 데이터 로드\n",
    "csv_results_name = 'csv/trainer_results.csv'\n",
    "csv_results_path =  os.path.join(raw_root_dir,csv_results_name)\n",
    "\n",
    "csv_world_results_name = 'csv/trainer_world_results.csv'\n",
    "csv_world_results_path =  os.path.join(raw_root_dir,csv_world_results_name)\n",
    "\n",
    "trainer_results_df = pd.read_csv(csv_results_path)\n",
    "trainer_world_results_df = pd.read_csv(csv_world_results_path)\n",
    "\n",
    "# user 데이터\n",
    "user_base_results_df = trainer_results_df.copy()\n",
    "user_world_results_df = trainer_world_results_df.copy()\n",
    "\n",
    "row = 0\n",
    "\n",
    "# main code\n",
    "with mp_pose.Pose(min_detection_confidence=0.9, min_tracking_confidence=0.9) as pose:\n",
    "    '''previous_frame0 = None\n",
    "    previous_frame1 = None'''\n",
    "    \n",
    "    while True:\n",
    "        ret0, frame0 = cap0.read()\n",
    "        if not ret0:\n",
    "            print(\"Failed to read from cap0\")\n",
    "            break\n",
    "        ret1, frame1 = cap1.read()\n",
    "        if not ret1:\n",
    "            print(\"Failed to read from cap1\")\n",
    "            break\n",
    "        # 시작 시점 측정\n",
    "        start_t = timeit.default_timer()\n",
    "            \n",
    "        #############################################################\n",
    "        ## Trainer 이미지 처리 (image0)\n",
    "        image0 = frame0\n",
    "        image1 = frame1\n",
    "        \n",
    "        \n",
    "        ############################################################\n",
    "        ## User 이미지 처리 (image1)\n",
    "        # Flip frame1 horizontally\n",
    "        frame1_resized = cv2.resize(frame1, (frame0.shape[1], frame0.shape[0]))\n",
    "        frame1_flipped_resized = cv2.flip(frame1_resized, 1)\n",
    "        \n",
    "        try:\n",
    "            # Now use frame1_flipped for further processing\n",
    "            image1, results1 = jk_module.mediapipe_detection(frame1_flipped_resized, pose)\n",
    "            mp_drawing.draw_landmarks(image1, results1.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(0,66,230), thickness=6, circle_radius=4), \n",
    "                                    mp_drawing.DrawingSpec(color=(0,0,255), thickness=6, circle_radius=4)) \n",
    "            landmarks = results1.pose_landmarks.landmark\n",
    "            world_landmarks = results1.pose_world_landmarks.landmark\n",
    "            \n",
    "            #csv_results_path = f'user_results{trial}.csv'\n",
    "            #csv_world_results_path =  f'user_world_results1{trial}.csv'\n",
    "            #jk_module.landmarks_save(csv_results_path, results1, row)\n",
    "            #jk_module.world_landmarks_save(csv_world_results_path, results1, row)\n",
    "\n",
    "            # Continue with the rest of your code, ensuring to use the flipped image where necessary\n",
    "        except:\n",
    "            pass\n",
    "        ############################################################\n",
    "        ## 데이터 로드\n",
    "        if row >= len(trainer_world_results_df):\n",
    "            break\n",
    "            \n",
    "        now_trainer_world = trainer_world_results_df.iloc[row].tolist()\n",
    "        now_trainer_base = trainer_results_df.iloc[row].tolist()\n",
    "\n",
    "        now_user_world = [coord for w_landmark in world_landmarks for coord in (w_landmark.x, w_landmark.y, w_landmark.z, w_landmark.visibility)]\n",
    "        #now_user_base = [coord for landmark in landmarks for coord in (landmark.x, landmark.y, landmark.z, landmark.visibility)]\n",
    "\n",
    "        now_user_base = []\n",
    "        for landmark in landmarks:\n",
    "            now_user_base.extend([landmark.x , landmark.y, landmark.z, landmark.visibility])\n",
    "        \n",
    "        user_world_results_df.loc[row] = now_user_world\n",
    "        user_base_results_df.loc[row] = now_user_base\n",
    "        \n",
    "            \n",
    "            \n",
    "        ###평가\n",
    "        ############################################################\n",
    "        ##2. score board 이미지 처리 (image2)\n",
    "        image2 = cv2.resize(frame2, (frame_width, frame_height))\n",
    "\n",
    "        \"\"\"입력\"\"\"\n",
    "        columns = [23,25,11,13,15,27, 24,26,12,14,16,28]\n",
    "        #OKS_list = jk_OKS.OKS_score(now_trainer_world, now_user_world, columns)\n",
    "        OKS_list_base = jk_OKS.OKS_2d_score(now_trainer_base, now_user_base, columns)\n",
    "        #jk_OKS.OkS_text(image2, OKS_list)\n",
    "\n",
    "        jk_OKS.OkS_text_base3(image2, OKS_list_base)\n",
    "\n",
    "\n",
    "        ############################################################\n",
    "        ##3. visual 이미지 처리 (image3)\n",
    "        image3 = np.ones((frame_height, frame_width, 3), dtype=np.uint8) * 255\n",
    "        \n",
    "        image3 = jk_draw.draw_person2(image3, now_trainer_base, frame_width, frame_height)\n",
    "        image3 = jk_draw.draw_person2(image3, now_user_base, frame_width, frame_height, color_keypoint=(0,66,230), color_connection=(0,0,255))\n",
    "                \n",
    "\n",
    "        ############################################################\n",
    "        ##4. concat 두 프레임을 좌우 결합\n",
    "        # Ensure all images are resized to the same height and width before concatenation\n",
    "        image0_resized = cv2.resize(image0, (frame_width, frame_height))\n",
    "        image1_resized = cv2.resize(image1, (frame_width, frame_height))\n",
    "        image2_resized = cv2.resize(image2, (frame_width, frame_height))\n",
    "        image3_resized = cv2.resize(image3, (frame_width, frame_height))\n",
    "\n",
    "        # Concatenate the resized images\n",
    "        combined_frame = np.hstack((image0_resized, image1_resized, image2_resized, image3_resized))\n",
    "        \n",
    "\n",
    "        # 프레임의 크기 조정\n",
    "        resized_frame = cv2.resize(combined_frame, (new_width, new_height))\n",
    "        ############################################################\n",
    "        ##5.시간 측정\n",
    "        # 종료 시점 측정\n",
    "        end_t = timeit.default_timer()\n",
    "        FPS = 1./(end_t - start_t )\n",
    "\n",
    "        # 조정된 프레임을 파일로 저장\n",
    "        out.write(resized_frame)\n",
    "        user_out.write(frame1_resized)\n",
    "        \n",
    "        cv2.imshow('test', resized_frame)\n",
    "        \n",
    "\n",
    "        row = row + 1\n",
    "\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        \n",
    "    cap0.release()\n",
    "    cap1.release()\n",
    "    out.release()  \n",
    "    user_out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "action_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
